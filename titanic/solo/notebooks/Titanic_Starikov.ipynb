{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "J-4mHSYbNFTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75ef2af-377c-4bcc-d5cd-362a994598b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  \n",
        "  print(\n",
        "      'User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn]))\n",
        "  )\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "hVGkYjtSNJwy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a2ea6328-c82a-4cba-810b-a62f31e5db60"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d4080579-51f0-4b34-9fdd-8a2e20512301\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d4080579-51f0-4b34-9fdd-8a2e20512301\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download \"titanic\""
      ],
      "metadata": {
        "id": "Tfvx567GNMUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c7ad3f-417b-42df-bcdb-074efc767da6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "titanic.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip titanic.zip"
      ],
      "metadata": {
        "id": "Lf0b36pCNPZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e9febc-39a5-4298-acd2-2dd46ace24d6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  titanic.zip\n",
            "replace gender_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "PjAcYNycNRuS"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Analysis"
      ],
      "metadata": {
        "id": "RUNCePJlVNPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# todo:\n",
        "# 1.\n",
        "# understand how to process features\n",
        "# Dmatrix?\n",
        "# reproduce analysis\n",
        "# filer rows, outliers (clean data)\n",
        "# try to combine train + test (bigger feature set)\n",
        "# https://www.kaggle.com/code/gunesevitan/titanic-advanced-feature-engineering-tutorial\n",
        "# https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
        "# feature importa\n",
        "# 2. \n",
        "# Grid search on features\n",
        "# 3.\n",
        "# Grid search on model params"
      ],
      "metadata": {
        "id": "uJXdM6pOjgwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "Om9MKWMdxdY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "def prepare_features_xgb(X: pd.DataFrame, target_value: str):\n",
        "    y = X[[target_value]]\n",
        "    X.drop(target_value, axis='columns', inplace=True)\n",
        "\n",
        "    categorical_pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "            (\"oh-encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    numeric_pipeline = Pipeline(\n",
        "        steps=[(\"impute\", SimpleImputer(strategy=\"mean\")),\n",
        "               (\"scale\", StandardScaler())]\n",
        "    )\n",
        "\n",
        "    cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
        "    num_cols = X.select_dtypes(include=\"number\").columns\n",
        "\n",
        "    full_processor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"numeric\", numeric_pipeline, num_cols),\n",
        "            (\"categorical\", categorical_pipeline, cat_cols),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    X_processed = full_processor.fit_transform(X)\n",
        "    y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(\n",
        "        y.values.reshape(-1, 1)\n",
        "    )\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_processed, y_processed, stratify=y_processed, random_state=1121218\n",
        "    )\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "IUxxdtGmXVKZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Engineering"
      ],
      "metadata": {
        "id": "nwpcXCjLzgpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "X_train, X_test, y_train, y_test = prepare_features_xgb(train_df.copy(), 'Survived')\n",
        "\n",
        "model = xgb.XGBClassifier(random_state=SEED)\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print('accuracy_score: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mx7-yfCzfna",
        "outputId": "4a9d07c5-d146-48ff-a14e-a1a5fabffc3e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None,\n",
            "              colsample_bytree=None, early_stopping_rounds=None,\n",
            "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
            "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
            "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, random_state=42, ...)\n",
            "accuracy_score:  0.8071748878923767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = prepare_features_xgb(train_df.copy(), 'Survived')\n",
        "\n",
        "model = RandomForestClassifier(random_state=SEED)\n",
        "model.fit(X_train, y_train)\n",
        "print(model)\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print('accuracy_score: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA1p19Ludi5B",
        "outputId": "c6227378-2145-4890-9a5c-245addfd232c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "<ipython-input-49-43a6226b8c5e>:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model.fit(X_train, y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(random_state=42)\n",
            "accuracy_score:  0.820627802690583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = prepare_features_xgb(train_df.copy(), 'Survived')\n",
        "\n",
        "\n",
        "def get_stacking():\n",
        "    # define the base models\n",
        "    level0 = list()\n",
        "    level0.append(('lr', LogisticRegression()))\n",
        "    level0.append(('knn', KNeighborsClassifier()))\n",
        "    level0.append(('cart', DecisionTreeClassifier()))\n",
        "    level0.append(('svm', SVC()))\n",
        "    level0.append(('bayes', GaussianNB()))\n",
        "    # define meta learner model\n",
        "    level1 = LogisticRegression()\n",
        "    # define the stacking ensemble\n",
        "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_models():\n",
        "    models = dict()\n",
        "    models['lr'] = LogisticRegression()\n",
        "    models['knn'] = KNeighborsClassifier()\n",
        "    models['cart'] = DecisionTreeClassifier()\n",
        "    models['svm'] = SVC()\n",
        "    models['bayes'] = GaussianNB()\n",
        "    models['stacking'] = get_stacking()\n",
        "    return models\n",
        "\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=SEED)\n",
        "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "    return scores\n",
        "\n",
        "\n",
        "models = get_models()\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "    scores = evaluate_model(model, X_train, y_train)\n",
        "    results.append(scores)\n",
        "    names.append(name)\n",
        "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# 0.815\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ5N0L6zgLin",
        "outputId": "82aec8f5-97b2-4c59-e28b-3a4f005db8d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">lr 0.808 (0.044)\n",
            ">knn 0.781 (0.042)\n",
            ">cart 0.805 (0.052)\n",
            ">svm 0.816 (0.041)\n",
            ">bayes 0.460 (0.042)\n",
            ">stacking 0.817 (0.033)\n"
          ]
        }
      ]
    }
  ]
}